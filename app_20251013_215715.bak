import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from io import StringIO
from helpers import coalesce_columns, compute_kpis, flag_anomalies, safe_float

st.set_page_config(page_title="Claims Risk Analyzer ‚Äî InsureTech AI", layout="wide")

st.title("üõ°Ô∏è Claims Risk Analyzer ‚Äî InsureTech AI (Demo)")
st.caption("Surface risky claims, understand loss drivers, and quantify ROI from day one.")

with st.expander("About this demo"):
    st.write("""
    **What this shows**
    - Upload a CSV or use a sample to explore claims/policy data.
    - KPI summary + interactive filters.
    - Outlier detection with transparent reason codes.
    - ROI calculator to translate findings into business impact.
    - Export flagged claims to CSV for investigation.
    
    **Notes**
    - This is an MVP demo. No PII required. Runs locally.
    - In production: add SSO, encryption, audit logs, connectors, and RBAC.
    """)

# Data input
uploaded = st.file_uploader("Upload a CSV (claims/policy data)", type=["csv"])
sample_btn = st.button("Use minimal sample data")

def load_sample_df():
    data = {
        "claim_id": range(1, 31),
        "claim_amount": np.random.lognormal(mean=8.5, sigma=0.6, size=30).round(2),
        "policy_premium": np.random.uniform(500, 2500, size=30).round(2),
        "policy_type": np.random.choice(["Auto", "Home", "Health"], size=30, p=[0.3, 0.2, 0.5]),
        "claim_type": np.random.choice(["Injury", "Property", "Theft", "Other"], size=30),
        "region": np.random.choice(["Northeast", "Midwest", "South", "West"], size=30),
        "state": np.random.choice(["NY", "CA", "TX", "FL", "IL", "PA"], size=30),
        "age": np.random.randint(18, 85, size=30),
        "tenure_months": np.random.randint(1, 120, size=30),
    }
    df = pd.DataFrame(data)
    # Add a few synthetic outliers
    df.loc[np.random.choice(df.index, 2, replace=False), "claim_amount"] *= 6
    return df

df = None
if uploaded is not None:
    try:
        df = pd.read_csv(uploaded)
    except Exception as e:
        st.error(f"Failed to read CSV: {e}")
elif sample_btn:
    df = load_sample_df()

if df is not None:
    df = coalesce_columns(df)

    # Sidebar filters
    with st.sidebar:
        st.header("Filters")
        filter_cols = []
        for col in ["policy_type", "claim_type", "region", "state"]:
            if col in df.columns:
                vals = sorted(df[col].dropna().unique().tolist())
                sel = st.multiselect(col.replace("_", " ").title(), vals, default=vals)
                filter_cols.append((col, sel))

        if filter_cols:
            mask = pd.Series([True] * len(df))
            for col, sel in filter_cols:
                mask &= df[col].isin(sel)
            df_f = df[mask].copy()
        else:
            df_f = df.copy()

        st.divider()
        st.subheader("Anomaly Detection Settings")
        z_threshold = safe_float(st.number_input("Z-score threshold", value=2.5, step=0.1))
        score_threshold = safe_float(st.number_input("IsolationForest score threshold (0-1)", value=0.65, step=0.05))
        if z_threshold is None: z_threshold = 2.5
        if score_threshold is None: score_threshold = 0.65

    # KPIs
    kpis = compute_kpis(df_f)
    kcols = st.columns(4)
    kcols[0].metric("Claims (rows)", f"{kpis.get('num_claims', 0):,}")
    if "avg_claim_amount" in kpis:
        kcols[1].metric("Avg Claim Amount", f"${kpis['avg_claim_amount']:,.0f}")
    if "total_claims_amount" in kpis:
        kcols[2].metric("Total Claim Amount", f"${kpis['total_claims_amount']:,.0f}")
    if kpis.get("loss_ratio_proxy") is not None:
        kcols[3].metric("Loss Ratio (proxy)", f"{kpis['loss_ratio_proxy']:.2f}")

    # Charts
    st.subheader("Insights")
    c1, c2 = st.columns(2)
    if "claim_amount" in df_f.columns and "claim_type" in df_f.columns:
        fig = px.box(df_f, x="claim_type", y="claim_amount", points="all", title="Claim Amount by Claim Type")
        c1.plotly_chart(fig, use_container_width=True)

    if "claim_amount" in df_f.columns and "policy_type" in df_f.columns:
        fig2 = px.violin(df_f, x="policy_type", y="claim_amount", box=True, points="all", title="Claim Amount by Policy Type")
        c2.plotly_chart(fig2, use_container_width=True)

    # Anomalies
    st.subheader("Investigation Shortlist")
    scored = flag_anomalies(df_f, z_threshold=z_threshold, score_threshold=score_threshold)
    st.write("**Flagged records** are displayed below with **risk scores** and **reason codes**.")
    flagged = scored[scored["flagged"]].copy().sort_values("risk_score", ascending=False)

    if not flagged.empty:
        st.dataframe(flagged.head(100))
        csv = flagged.to_csv(index=False).encode("utf-8")
        st.download_button("Download flagged CSV", csv, "flagged_claims.csv", "text/csv")
    else:
        st.info("No records flagged at current thresholds. Try lowering thresholds or inspecting box/violin plots.")

    # ROI calculator
    st.subheader("ROI Calculator")
    col_a, col_b, col_c, col_d = st.columns(4)
    avg_fraud_rate = col_a.number_input("Est. suspicious rate (%)", value=2.0, min_value=0.0, max_value=100.0, step=0.5)
    avg_claim_amt = col_b.number_input("Avg suspicious claim amount ($)", value=float(kpis.get('avg_claim_amount', 5000.0)), step=100.0)
    detection_improvement = col_c.number_input("Detection improvement vs. baseline (%)", value=25.0, min_value=0.0, max_value=100.0, step=1.0)
    monthly_claim_volume = col_d.number_input("Monthly claim volume", value=500, step=10)

    # Simple savings model
    suspicious_claims = monthly_claim_volume * (avg_fraud_rate / 100.0)
    improved_catches = suspicious_claims * (detection_improvement / 100.0)
    savings = improved_catches * avg_claim_amt

    st.metric("Estimated Monthly Savings", f"${savings:,.0f}")
    st.caption("Adjust assumptions to match your environment. We can calibrate with historicals during pilot.")

else:
    st.info("Upload a CSV or click **Use minimal sample data** to start.")
